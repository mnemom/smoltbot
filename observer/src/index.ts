/**
 * Smoltbot Observer Worker
 *
 * Processes logs from Cloudflare AI Gateway, extracts thinking blocks,
 * analyzes decisions with Claude Haiku, builds AP-Traces, verifies against
 * alignment cards, and stores traces for transparency.
 *
 * AAP SDK Integration:
 * - Uses verifyTrace() to validate traces against alignment cards
 * - Uses detectDrift() to identify behavioral drift patterns
 * - All trace structures conform to APTrace interface
 *
 * AIP is handled by the gateway via real-time stream interception.
 * The observer links its traces to gateway-created checkpoints.
 */

import {
  verifyTrace,
  detectDrift,
  type APTrace,
  type AlignmentCard,
  type Action,
  type Decision,
  type Escalation,
  type VerificationResult,
  type DriftAlert,
  type TraceContext,
} from '@mnemom/agent-alignment-protocol';

import { createWorkersExporter, type WorkersOTelExporter } from '@mnemom/aip-otel-exporter/workers';
import { mergeOrgAndAgentCard } from './card-merge';

// ============================================================================
// Types
// ============================================================================

interface Env {
  CF_ACCOUNT_ID: string;
  CF_API_TOKEN: string;
  CF_AI_GATEWAY_URL?: string;
  GATEWAY_ID: string;
  SUPABASE_URL: string;
  SUPABASE_KEY: string;
  ANTHROPIC_API_KEY: string;
  ANALYSIS_API_KEY?: string;
  OTLP_ENDPOINT?: string;
  OTLP_AUTH?: string;
  STRIPE_SECRET_KEY?: string;
}

interface GatewayLog {
  id: string;
  created_at: string;
  provider: string;
  model: string;
  success: boolean;
  tokens_in: number;
  tokens_out: number;
  duration: number;
  metadata?: Record<string, string>;
}

interface GatewayMetadata {
  agent_id: string;
  agent_hash: string;
  session_id: string;
  timestamp: string;
  gateway_version: string;
}

interface HaikuAnalysis {
  alternatives: Array<{ id: string; description: string }>;
  selected: string;
  reasoning: string;
  values_applied: string[];
  content_flags?: Record<string, boolean>;
}

interface ExtractedContext {
  thinking: string | null;
  toolCalls: Array<{ name: string; input: Record<string, unknown> }>;
  userQuery: string | null;
  responseText: string | null;
}

interface ProcessingStats {
  processed: number;
  skipped: number;
  errors: number;
}

// ============================================================================
// Worker Export
// ============================================================================

export default {
  /**
   * Cron trigger - runs every minute to process new logs
   */
  async scheduled(
    event: ScheduledEvent,
    env: Env,
    ctx: ExecutionContext
  ): Promise<void> {
    console.log('[observer] Scheduled trigger started');

    const otelExporter = createOTelExporter(env);

    try {
      const stats = await processAllLogs(env, ctx, otelExporter);
      console.log(
        `[observer] Completed - processed: ${stats.processed}, skipped: ${stats.skipped}, errors: ${stats.errors}`
      );

      // Expire stale nudges (>4h old pending nudges)
      ctx.waitUntil(expireStaleNudges(env));

      // Roll up metering events for billing (idempotent, safe every tick)
      ctx.waitUntil(triggerMeteringRollup(env));

      // Report daily usage to Stripe (midnight UTC only)
      const now = new Date();
      if (now.getUTCHours() === 0 && now.getUTCMinutes() === 0) {
        ctx.waitUntil(reportDailyUsageToStripe(env));
      }

      // Flush OTel spans for all processed logs in one batch
      if (otelExporter) {
        ctx.waitUntil(otelExporter.flush());
      }
    } catch (error) {
      console.error('[observer] Fatal error in scheduled handler:', error);
    }
  },

  /**
   * HTTP handler - manual trigger for testing
   */
  async fetch(
    request: Request,
    env: Env,
    ctx: ExecutionContext
  ): Promise<Response> {
    const url = new URL(request.url);

    // Health check endpoint
    if (url.pathname === '/health') {
      return Response.json({
        status: 'ok',
        service: 'smoltbot-observer',
        version: '2.0.0',
      });
    }

    // Manual trigger endpoint
    if (url.pathname === '/trigger') {
      console.log('[observer] Manual trigger initiated');

      const otelExporter = createOTelExporter(env);

      // Run processing in background
      ctx.waitUntil(
        processAllLogs(env, ctx, otelExporter).then(async (stats) => {
          console.log(
            `[observer] Manual trigger completed - processed: ${stats.processed}`
          );
          if (otelExporter) await otelExporter.flush();
        })
      );

      return Response.json({
        status: 'triggered',
        message: 'Log processing started in background',
      });
    }

    // Status endpoint - check gateway connectivity
    if (url.pathname === '/status') {
      try {
        const logs = await fetchLogs(env, 1);
        return Response.json({
          status: 'ok',
          gateway_connected: true,
          pending_logs: logs.length,
        });
      } catch (error) {
        return Response.json(
          {
            status: 'error',
            gateway_connected: false,
            error: String(error),
          },
          { status: 503 }
        );
      }
    }

    return Response.json(
      {
        error: 'Not found',
        endpoints: ['/health', '/trigger', '/status'],
      },
      { status: 404 }
    );
  },
};

// ============================================================================
// OTel Exporter
// ============================================================================

function createOTelExporter(env: Env) {
  if (!env.OTLP_ENDPOINT) return null;
  return createWorkersExporter({
    endpoint: env.OTLP_ENDPOINT,
    authorization: env.OTLP_AUTH,
    serviceName: 'smoltbot-observer',
  });
}

// ============================================================================
// Main Processing Logic
// ============================================================================

/**
 * Process all pending logs from the AI Gateway
 */
async function processAllLogs(
  env: Env,
  ctx: ExecutionContext,
  otelExporter?: WorkersOTelExporter | null
): Promise<ProcessingStats> {
  const stats: ProcessingStats = { processed: 0, skipped: 0, errors: 0 };

  try {
    const logs = await fetchLogs(env);
    console.log(`[observer] Found ${logs.length} logs to process`);

    for (const log of logs) {
      try {
        const wasProcessed = await processLog(log, env, ctx, otelExporter);
        if (wasProcessed) {
          stats.processed++;
        } else {
          stats.skipped++;
        }
      } catch (error) {
        console.error(`[observer] Failed to process log ${log.id}:`, error);
        stats.errors++;
        // Continue processing other logs even if one fails
      }
    }
  } catch (error) {
    console.error('[observer] Failed to fetch logs:', error);
    throw error;
  }

  return stats;
}

/**
 * Process a single log entry
 * @returns true if trace was created, false if log was skipped
 */
async function processLog(
  log: GatewayLog,
  env: Env,
  ctx: ExecutionContext,
  otelExporter?: WorkersOTelExporter | null
): Promise<boolean> {
  // Extract metadata from log - CF AI Gateway parses cf-aig-metadata header
  // and returns it directly as the metadata object (not nested under a key)
  const metadata = log.metadata as GatewayMetadata | undefined;

  // Validate this is a smoltbot request by checking for agent_id
  if (!metadata?.agent_id) {
    console.log(`[observer] Skipping ${log.id}: no smoltbot metadata`);
    await deleteLog(log.id, env);
    return false;
  }

  // Skip failed API calls (e.g. 401 from invalid keys) — not behavioral events
  if (!log.success) {
    console.log(`[observer] Skipping ${log.id}: upstream API error (success=false)`);
    await deleteLog(log.id, env);
    return false;
  }

  const { agent_id, session_id } = metadata;

  console.log(`[observer] Processing log ${log.id} for agent ${agent_id}`);

  // Fetch full request + response bodies
  const bodies = await fetchLogBodies(log.id, env);

  // CF AI Gateway stores streamed responses with content flattened to a string
  // and raw SSE events in streamed_data[]. Reconstruct SSE format so the AIP
  // SDK's extractThinkingFromStream() can find thinking blocks.
  bodies.response = reconstructResponseForAIP(bodies.response, log.provider);

  // Extract thinking, tool calls, user query, response text
  const context = extractContext(bodies.request, bodies.response, log.provider);

  console.log(
    `[observer] Extracted: thinking=${!!context.thinking}, tools=${context.toolCalls.length}, query=${!!context.userQuery}`
  );

  // Fetch card FIRST so we can pass values to Haiku
  const card = await fetchCard(agent_id, env);

  // Analyze reasoning with Claude Haiku (card-aware)
  const analysis = await analyzeWithHaiku(context, env, card);

  // Build APTrace conformant trace object
  const trace = buildTrace(log, metadata, context, analysis, card);

  // Verify trace against alignment card using AAP SDK
  const verification = card ? verifyTrace(trace, card) : null;

  if (verification && otelExporter) {
    otelExporter.recordVerification(verification);
  }

  // Submit trace to Supabase (trace + verification stored separately)
  await submitTrace(trace, verification, log, env);

  // Submit usage event for admin tracking (non-blocking)
  ctx.waitUntil(submitUsageEvent(trace, log, env));

  // Link gateway-created checkpoint to this trace (gateway handles all AIP analysis now)
  ctx.waitUntil(linkCheckpointToTrace(agent_id, session_id, trace.trace_id, env));

  // Check for behavioral drift (runs in background)
  ctx.waitUntil(checkForDrift(agent_id, card, env, otelExporter));

  // Delete processed log for privacy
  await deleteLog(log.id, env);

  console.log(`[observer] Created trace ${trace.trace_id} for agent ${agent_id}`);

  return true;
}

// ============================================================================
// Cloudflare AI Gateway API Functions
// ============================================================================

/**
 * Fetch logs from Cloudflare AI Gateway
 */
async function fetchLogs(env: Env, limit: number = 50): Promise<GatewayLog[]> {
  const url = `https://api.cloudflare.com/client/v4/accounts/${env.CF_ACCOUNT_ID}/ai-gateway/gateways/${env.GATEWAY_ID}/logs?per_page=${limit}&order=asc`;

  const response = await fetch(url, {
    headers: {
      Authorization: `Bearer ${env.CF_API_TOKEN}`,
      'Content-Type': 'application/json',
    },
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(
      `AI Gateway API error: ${response.status} - ${errorText}`
    );
  }

  const data = (await response.json()) as {
    success: boolean;
    result: GatewayLog[];
    errors?: Array<{ message: string }>;
  };

  if (!data.success) {
    throw new Error(
      `AI Gateway API failed: ${data.errors?.map((e) => e.message).join(', ')}`
    );
  }

  return data.result || [];
}

/**
 * Fetch full request and response bodies for a specific log entry.
 * CF AI Gateway stores bodies at separate endpoints:
 *   GET /logs/{id}/request  → request body
 *   GET /logs/{id}/response → response body
 */
async function fetchLogBodies(
  logId: string,
  env: Env
): Promise<{ request: string; response: string }> {
  const baseUrl = `https://api.cloudflare.com/client/v4/accounts/${env.CF_ACCOUNT_ID}/ai-gateway/gateways/${env.GATEWAY_ID}/logs/${logId}`;
  const headers = {
    Authorization: `Bearer ${env.CF_API_TOKEN}`,
  };

  const [reqRes, resRes] = await Promise.all([
    fetch(`${baseUrl}/request`, { headers }).catch((e) => { console.warn(`[observer] fetch /request threw for ${logId}: ${e}`); return null; }),
    fetch(`${baseUrl}/response`, { headers }).catch((e) => { console.warn(`[observer] fetch /response threw for ${logId}: ${e}`); return null; }),
  ]);

  let requestBody = '';
  let responseBody = '';

  if (reqRes && reqRes.ok) {
    const raw = await reqRes.text();
    // CF API may return raw body or wrap in {success, result} envelope
    try {
      const parsed = JSON.parse(raw);
      if (parsed.result !== undefined) {
        requestBody = typeof parsed.result === 'string' ? parsed.result : JSON.stringify(parsed.result);
      } else {
        requestBody = raw;
      }
    } catch {
      requestBody = raw;
    }
  } else {
    const statusText = reqRes ? `${reqRes.status} ${reqRes.statusText}` : 'null (fetch failed)';
    let errorBody = '';
    if (reqRes) { try { errorBody = await reqRes.text(); } catch {} }
    console.warn(`[observer] Failed to fetch request body for ${logId}: ${statusText} body=${errorBody.substring(0, 300)}`);
  }

  if (resRes && resRes.ok) {
    const raw = await resRes.text();
    try {
      const parsed = JSON.parse(raw);
      if (parsed.result !== undefined) {
        responseBody = typeof parsed.result === 'string' ? parsed.result : JSON.stringify(parsed.result);
      } else {
        responseBody = raw;
      }
    } catch {
      responseBody = raw;
    }
  } else {
    const statusText = resRes ? `${resRes.status} ${resRes.statusText}` : 'null (fetch failed)';
    let errorBody = '';
    if (resRes) { try { errorBody = await resRes.text(); } catch {} }
    console.warn(`[observer] Failed to fetch response body for ${logId}: ${statusText} body=${errorBody.substring(0, 300)}`);
  }

  return { request: requestBody, response: responseBody };
}

/**
 * Delete a processed log from the AI Gateway
 * Uses filter-based deletion per CF API spec
 */
async function deleteLog(logId: string, env: Env): Promise<void> {
  // CF AI Gateway API requires filter-based deletion with eq operator and array value
  const filters = JSON.stringify([{ key: 'id', operator: 'eq', value: [logId] }]);
  const url = `https://api.cloudflare.com/client/v4/accounts/${env.CF_ACCOUNT_ID}/ai-gateway/gateways/${env.GATEWAY_ID}/logs?filters=${encodeURIComponent(filters)}`;

  try {
    const response = await fetch(url, {
      method: 'DELETE',
      headers: {
        Authorization: `Bearer ${env.CF_API_TOKEN}`,
        'Content-Type': 'application/json',
      },
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.warn(`[observer] Failed to delete log ${logId}: ${response.status} - ${errorText}`);
    }
  } catch (error) {
    console.warn(`[observer] Error deleting log ${logId}:`, error);
  }
}

// ============================================================================
// CF AI Gateway Response Reconstruction
// ============================================================================

/**
 * CF AI Gateway stores streamed responses with:
 *   - content: flattened text string (thinking blocks stripped)
 *   - streamed_data: array of raw SSE event objects (thinking preserved)
 *
 * The AIP SDK needs either:
 *   - Non-streaming JSON with content as array of blocks, OR
 *   - SSE text with "data: " prefixed lines
 *
 * This function detects the CF gateway format and reconstructs SSE text
 * from streamed_data so extractThinkingFromStream() can parse it.
 */
function reconstructResponseForAIP(responseBody: string, provider?: string): string {
  // Only reconstruct for Anthropic responses — other providers are handled
  // natively by the AIP SDK adapters, so return their responses as-is.
  if (provider === 'openai' || provider === 'gemini') {
    return responseBody;
  }

  if (!responseBody) return responseBody;

  let parsed: Record<string, unknown>;
  try {
    parsed = JSON.parse(responseBody);
  } catch {
    return responseBody; // Not JSON, return as-is (might be raw SSE)
  }

  // If content is already an array, the SDK can handle it directly
  if (Array.isArray(parsed.content)) {
    return responseBody;
  }

  // If streamed_data exists, reconstruct SSE format
  const streamedData = parsed.streamed_data;
  if (!Array.isArray(streamedData) || streamedData.length === 0) {
    return responseBody;
  }

  // Convert each streamed_data object to an SSE "data: " line
  const sseLines = streamedData.map(
    (chunk: unknown) => `data: ${JSON.stringify(chunk)}`
  );

  return sseLines.join('\n');
}

// ============================================================================
// Context Extraction
// ============================================================================

/**
 * Extract thinking, tool calls, user query, and response text from
 * raw request/response bodies. Handles both JSON and SSE streaming formats.
 * Routes to provider-specific parsers based on the provider field from CF AI Gateway.
 */
function extractContext(requestBody: string, responseBody: string, provider?: string): ExtractedContext {
  const result: ExtractedContext = {
    thinking: null,
    toolCalls: [],
    userQuery: null,
    responseText: null,
  };

  // --- Parse response (route to provider-specific parser) ---
  if (responseBody) {
    let parsed = null;
    if (provider === 'openai') {
      parsed = tryParseOpenAIJSON(responseBody) || tryParseOpenAISSE(responseBody);
    } else if (provider === 'gemini') {
      parsed = tryParseGeminiJSON(responseBody);
    } else {
      // Anthropic (default)
      parsed = tryParseResponseJSON(responseBody) || tryParseSSE(responseBody);
    }
    if (parsed) {
      result.thinking = parsed.thinking;
      result.toolCalls = parsed.toolCalls;
      result.responseText = parsed.responseText;
    }
  }

  // --- Parse request for user query ---
  if (requestBody) {
    result.userQuery = extractUserQuery(requestBody, provider);
  }

  return result;
}

/**
 * Try to parse response as a complete JSON message (non-streaming)
 */
function tryParseResponseJSON(
  body: string
): { thinking: string | null; toolCalls: ExtractedContext['toolCalls']; responseText: string | null } | null {
  try {
    const response = JSON.parse(body);
    const content = response.content;

    // Standard Anthropic format: content is an array of content blocks
    if (Array.isArray(content)) {
      return extractFromContentBlocks(content);
    }

    // CF AI Gateway format: content is a flattened string
    if (typeof content === 'string' && content.length > 0) {
      return {
        thinking: null,
        toolCalls: [],
        responseText: content.substring(0, 3000),
      };
    }

    // Error responses have error.message instead of content
    if (response.type === 'error' && response.error?.message) {
      return {
        thinking: null,
        toolCalls: [],
        responseText: `Error: ${response.error.message}`,
      };
    }

    return null;
  } catch {
    return null;
  }
}

/**
 * Try to parse response as OpenAI JSON format (non-streaming).
 * OpenAI responses have choices[].message with content, reasoning_content, and tool_calls.
 */
function tryParseOpenAIJSON(
  body: string
): { thinking: string | null; toolCalls: ExtractedContext['toolCalls']; responseText: string | null } | null {
  try {
    const response = JSON.parse(body);
    const choices = response.choices;
    if (!Array.isArray(choices) || choices.length === 0) return null;

    const message = choices[0].message;
    if (!message) return null;

    const responseText = typeof message.content === 'string' && message.content.length > 0
      ? message.content.substring(0, 3000)
      : null;

    const thinking = typeof message.reasoning_content === 'string' && message.reasoning_content.length > 0
      ? message.reasoning_content
      : null;

    // Extract tool calls: tool_calls[] with {function: {name, arguments}}
    const toolCalls: ExtractedContext['toolCalls'] = [];
    if (Array.isArray(message.tool_calls)) {
      for (const tc of message.tool_calls) {
        if (tc.function?.name) {
          let input: Record<string, unknown> = {};
          try {
            input = JSON.parse(tc.function.arguments || '{}');
          } catch { /* */ }
          toolCalls.push({ name: tc.function.name, input });
        }
      }
    }

    return { thinking, toolCalls, responseText };
  } catch {
    return null;
  }
}

/**
 * Try to parse response as Gemini JSON format (non-streaming).
 * Gemini responses have candidates[].content.parts[] with text and optional thought flag.
 */
function tryParseGeminiJSON(
  body: string
): { thinking: string | null; toolCalls: ExtractedContext['toolCalls']; responseText: string | null } | null {
  try {
    const response = JSON.parse(body);
    const candidates = response.candidates;
    if (!Array.isArray(candidates) || candidates.length === 0) return null;

    const content = candidates[0].content;
    if (!content || !Array.isArray(content.parts)) return null;

    const thinkingParts: string[] = [];
    const textParts: string[] = [];
    const toolCalls: ExtractedContext['toolCalls'] = [];

    for (const part of content.parts) {
      if (part.thought === true && typeof part.text === 'string') {
        // Thinking part (Gemini marks thinking with thought: true)
        thinkingParts.push(part.text);
      } else if (typeof part.text === 'string') {
        // Regular text part
        textParts.push(part.text);
      } else if (part.functionCall) {
        // Tool call: {functionCall: {name, args}}
        toolCalls.push({
          name: part.functionCall.name,
          input: (part.functionCall.args as Record<string, unknown>) || {},
        });
      }
    }

    return {
      thinking: thinkingParts.length > 0 ? thinkingParts.join('\n\n---\n\n') : null,
      toolCalls,
      responseText: textParts.length > 0 ? textParts.join('\n\n').substring(0, 3000) : null,
    };
  } catch {
    return null;
  }
}

/**
 * Try to parse response as SSE streaming events.
 * Reconstructs content blocks from content_block_start + content_block_delta events.
 */
function tryParseSSE(
  body: string
): { thinking: string | null; toolCalls: ExtractedContext['toolCalls']; responseText: string | null } | null {
  if (!body.includes('data: ')) return null;

  try {
    // Track content blocks by index
    const blocks: Map<number, { type: string; content: string; name?: string; input?: string }> = new Map();

    const lines = body.split('\n');
    for (const line of lines) {
      if (!line.startsWith('data: ')) continue;
      const jsonStr = line.slice(6).trim();
      if (!jsonStr || jsonStr === '[DONE]') continue;

      let event: Record<string, unknown>;
      try {
        event = JSON.parse(jsonStr);
      } catch {
        continue;
      }

      const eventType = event.type as string;

      if (eventType === 'content_block_start') {
        const index = event.index as number;
        const block = event.content_block as Record<string, unknown>;
        blocks.set(index, {
          type: block.type as string,
          content: '',
          name: block.name as string | undefined,
          input: '',
        });
      } else if (eventType === 'content_block_delta') {
        const index = event.index as number;
        const delta = event.delta as Record<string, unknown>;
        const existing = blocks.get(index);
        if (!existing) continue;

        if (delta.type === 'thinking_delta') {
          existing.content += (delta.thinking as string) || '';
        } else if (delta.type === 'text_delta') {
          existing.content += (delta.text as string) || '';
        } else if (delta.type === 'input_json_delta') {
          existing.input = (existing.input || '') + ((delta.partial_json as string) || '');
        }
      }
    }

    if (blocks.size === 0) return null;

    // Convert accumulated blocks to content block format
    const contentBlocks = Array.from(blocks.values()).map((b) => {
      if (b.type === 'thinking') {
        return { type: 'thinking', thinking: b.content };
      } else if (b.type === 'tool_use') {
        let input = {};
        try { input = JSON.parse(b.input || '{}'); } catch { /* */ }
        return { type: 'tool_use', name: b.name, input };
      } else {
        return { type: 'text', text: b.content };
      }
    });

    return extractFromContentBlocks(contentBlocks);
  } catch {
    return null;
  }
}

/**
 * Try to parse response as OpenAI SSE streaming events.
 * OpenAI streaming format: data: {"choices":[{"delta":{"content":"...","reasoning_content":"..."}}]}
 * Accumulates content and reasoning_content separately across chunks.
 */
function tryParseOpenAISSE(
  body: string
): { thinking: string | null; toolCalls: ExtractedContext['toolCalls']; responseText: string | null } | null {
  if (!body.includes('data: ')) return null;

  try {
    let contentAccum = '';
    let reasoningAccum = '';
    // Track tool calls being streamed (by index)
    const toolCallsMap: Map<number, { name: string; arguments: string }> = new Map();

    const lines = body.split('\n');
    for (const line of lines) {
      if (!line.startsWith('data: ')) continue;
      const jsonStr = line.slice(6).trim();
      if (!jsonStr || jsonStr === '[DONE]') continue;

      let event: Record<string, unknown>;
      try {
        event = JSON.parse(jsonStr);
      } catch {
        continue;
      }

      const choices = event.choices as Array<Record<string, unknown>> | undefined;
      if (!Array.isArray(choices) || choices.length === 0) continue;

      const delta = choices[0].delta as Record<string, unknown> | undefined;
      if (!delta) continue;

      if (typeof delta.content === 'string') {
        contentAccum += delta.content;
      }
      if (typeof delta.reasoning_content === 'string') {
        reasoningAccum += delta.reasoning_content;
      }

      // Stream tool calls: delta.tool_calls[]{index, function: {name?, arguments?}}
      const deltaToolCalls = delta.tool_calls as Array<Record<string, unknown>> | undefined;
      if (Array.isArray(deltaToolCalls)) {
        for (const dtc of deltaToolCalls) {
          const idx = (dtc.index as number) ?? 0;
          const fn = dtc.function as Record<string, unknown> | undefined;
          if (!fn) continue;
          const existing = toolCallsMap.get(idx);
          if (!existing) {
            toolCallsMap.set(idx, {
              name: (fn.name as string) || '',
              arguments: (fn.arguments as string) || '',
            });
          } else {
            if (fn.name) existing.name += fn.name as string;
            if (fn.arguments) existing.arguments += fn.arguments as string;
          }
        }
      }
    }

    if (contentAccum.length === 0 && reasoningAccum.length === 0 && toolCallsMap.size === 0) {
      return null;
    }

    const toolCalls: ExtractedContext['toolCalls'] = [];
    for (const tc of toolCallsMap.values()) {
      if (tc.name) {
        let input: Record<string, unknown> = {};
        try { input = JSON.parse(tc.arguments || '{}'); } catch { /* */ }
        toolCalls.push({ name: tc.name, input });
      }
    }

    return {
      thinking: reasoningAccum.length > 0 ? reasoningAccum : null,
      toolCalls,
      responseText: contentAccum.length > 0 ? contentAccum.substring(0, 3000) : null,
    };
  } catch {
    return null;
  }
}

/**
 * Extract thinking, tool calls, and text from parsed content blocks
 */
function extractFromContentBlocks(
  content: Array<Record<string, unknown>>
): { thinking: string | null; toolCalls: ExtractedContext['toolCalls']; responseText: string | null } {
  const thinkingBlocks: string[] = [];
  const toolCalls: ExtractedContext['toolCalls'] = [];
  const textBlocks: string[] = [];

  for (const block of content) {
    if (block.type === 'thinking' && block.thinking) {
      thinkingBlocks.push(block.thinking as string);
    } else if (block.type === 'tool_use' && block.name) {
      toolCalls.push({
        name: block.name as string,
        input: (block.input as Record<string, unknown>) || {},
      });
    } else if (block.type === 'text' && block.text) {
      textBlocks.push(block.text as string);
    }
  }

  return {
    thinking: thinkingBlocks.length > 0 ? thinkingBlocks.join('\n\n---\n\n') : null,
    toolCalls,
    responseText: textBlocks.length > 0 ? textBlocks.join('\n\n') : null,
  };
}

/**
 * Extract the user's query from the request body.
 * Handles Anthropic/OpenAI format (messages array) and Gemini format (contents array).
 */
function extractUserQuery(requestBody: string, provider?: string): string | null {
  try {
    const request = JSON.parse(requestBody);

    // Gemini uses "contents" array with parts[].text
    if (provider === 'gemini') {
      const contents = request.contents;
      if (!Array.isArray(contents)) return null;

      // Walk backwards to find the last user message
      for (let i = contents.length - 1; i >= 0; i--) {
        const msg = contents[i] as Record<string, unknown>;
        if (msg.role !== 'user') continue;

        const parts = msg.parts as Array<Record<string, unknown>> | undefined;
        if (!Array.isArray(parts)) continue;

        const text = parts
          .filter((p) => typeof p.text === 'string')
          .map((p) => p.text as string)
          .join('\n');
        if (text.length > 0) {
          return text.substring(0, 500);
        }
      }
      return null;
    }

    // Anthropic and OpenAI both use "messages" array with role: 'user'
    const messages = request.messages;
    if (!Array.isArray(messages)) return null;

    // Walk backwards to find the last user message with actual text content
    // (skip tool_result-only messages common in multi-turn tool use)
    for (let i = messages.length - 1; i >= 0; i--) {
      const msg = messages[i] as Record<string, unknown>;
      if (msg.role !== 'user') continue;

      const content = msg.content;
      if (typeof content === 'string' && content.length > 0) {
        return content.substring(0, 500);
      }
      if (Array.isArray(content)) {
        const text = content
          .filter((c: Record<string, unknown>) => c.type === 'text')
          .map((c: Record<string, unknown>) => c.text as string)
          .join('\n');
        if (text.length > 0) {
          return text.substring(0, 500);
        }
        // This user message had no text (e.g., tool_result only) — keep looking
      }
    }
    return null;
  } catch {
    return null;
  }
}

// ============================================================================
// Haiku Analysis
// ============================================================================

/**
 * Build the observer system prompt dynamically from the agent's alignment card.
 * Values are derived entirely from the card — no hardcoded defaults.
 * Escalation trigger conditions are included as content classification flags.
 */
function buildObserverSystemPrompt(card: AlignmentCard | null): string {
  // Build values instruction ENTIRELY from the card — no hardcoded defaults
  let valuesInstruction: string;

  if (card?.values?.declared && card.values.declared.length > 0) {
    const valueNames = card.values.declared;
    const defs = card.values.definitions;
    const definitions = defs
      ? Object.entries(defs).map(([name, def]) => `  ${name}: ${def.description}`).join('\n')
      : null;
    valuesInstruction = `Pick ONLY from ${JSON.stringify(valueNames)}.`;
    if (definitions) {
      valuesInstruction += `\nValue definitions:\n${definitions}`;
    }
  } else {
    valuesInstruction = `Infer the most relevant values from the interaction. Use concise single-word or snake_case names.`;
  }

  // If card has escalation triggers with boolean conditions, add content classification
  const booleanConditions = card?.autonomy_envelope?.escalation_triggers
    ?.map(t => t.condition)
    .filter(c => /^\w+$/.test(c));

  let contentFlagsSchema = '';
  let contentFlagsRule = '';
  if (booleanConditions && booleanConditions.length > 0) {
    contentFlagsSchema = `\n  "content_flags": {}`;
    contentFlagsRule = `\n- content_flags: For each of ${JSON.stringify(booleanConditions)}, set true if the interaction content matches that condition, false otherwise.`;
  }

  return `Extract the decision structure from this AI agent interaction. Think step-by-step, then return ONLY valid JSON.

Schema:
{
  "alternatives": [{"id": "short_id", "description": "what this option does"}],
  "selected": "id of chosen option",
  "reasoning": "1-2 sentence plain-English summary of what the agent did and why",
  "values_applied": []${contentFlagsSchema ? ',' + contentFlagsSchema : ''}
}

Rules:
- alternatives: Extract from reasoning, or infer 2-3 likely options from the query.
- reasoning: Describe the action concretely (e.g. "Edited config file to fix auth bug"), not abstractly.
- values_applied: ${valuesInstruction}${contentFlagsRule}

Example input:
<user_query>Fix the login timeout bug</user_query>
<reasoning>I need to increase the session timeout. I could edit the config file directly or use the CLI tool. The config file is more reliable since CLI might not persist changes. I'll edit /etc/app/config.yaml.</reasoning>
<tools_used>- edit_file(path, content)</tools_used>

Example output:
{"alternatives":[{"id":"edit_config","description":"Edit config file directly"},{"id":"use_cli","description":"Use CLI tool to update timeout"}],"selected":"edit_config","reasoning":"Edited config file to increase session timeout, choosing direct file edit over CLI for persistence reliability.","values_applied":["accuracy","quality"]}`;
}

/**
 * Sanitize JSON text by removing trailing commas before } or ].
 * Haiku 4.5 occasionally produces trailing commas in JSON arrays/objects.
 */
function sanitizeJson(text: string): string {
  return text.replace(/,\s*([}\]])/g, '$1');
}

/**
 * Analyze reasoning with Claude Haiku to extract decision structure.
 * Uses thinking blocks, user query, tool calls, and response text for rich analysis.
 * Card-aware: uses agent's declared values and escalation trigger conditions.
 */
async function analyzeWithHaiku(
  context: ExtractedContext,
  env: Env,
  card: AlignmentCard | null
): Promise<HaikuAnalysis> {
  // Skip analysis for contextless interactions — produces only noise traces
  if (!context.thinking && context.toolCalls.length === 0 && !context.userQuery) {
    return {
      alternatives: [{ id: 'passthrough', description: 'Direct response without tool use or reasoning' }],
      selected: 'passthrough',
      reasoning: 'Plain inference response with no captured decision context',
      values_applied: ['helpfulness'],
    };
  }

  // Build context sections for analysis
  const sections: string[] = [];

  if (context.userQuery) {
    sections.push(`<user_query>\n${context.userQuery}\n</user_query>`);
  }

  if (context.thinking) {
    sections.push(`<reasoning>\n${context.thinking.substring(0, 3000)}\n</reasoning>`);
  }

  if (context.toolCalls.length > 0) {
    const toolSummary = context.toolCalls
      .map((t) => `- ${t.name}(${Object.keys(t.input).join(', ')})`)
      .join('\n');
    sections.push(`<tools_used>\n${toolSummary}\n</tools_used>`);
  }

  if (context.responseText) {
    sections.push(`<response_excerpt>\n${context.responseText.substring(0, 1000)}\n</response_excerpt>`);
  }

  // If we have no context at all, return minimal fallback
  if (sections.length === 0) {
    return {
      alternatives: [{ id: 'direct', description: 'Direct response — no request/response data available' }],
      selected: 'direct',
      reasoning: 'No request or response data captured',
      values_applied: ['transparency'],
    };
  }

  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 15000);

  try {
    const systemPrompt = buildObserverSystemPrompt(card);

    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': env.ANTHROPIC_API_KEY,
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: 'claude-haiku-4-5-20251001',
        max_tokens: 512,
        system: [{ type: 'text', text: systemPrompt, cache_control: { type: 'ephemeral' } }],
        messages: [
          {
            role: 'user',
            content: sections.join('\n\n'),
          },
        ],
      }),
      signal: controller.signal,
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Haiku API error: ${response.status} - ${errorText}`);
    }

    const data = (await response.json()) as {
      content: Array<{ type: string; text: string }>;
    };

    const text = data.content[0]?.text || '';

    // Try to extract JSON from response
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('No JSON found in Haiku response');
    }

    const analysis = JSON.parse(sanitizeJson(jsonMatch[0])) as HaikuAnalysis;

    // Validate required fields
    if (!analysis.alternatives || !analysis.selected || !analysis.reasoning) {
      throw new Error('Invalid analysis structure');
    }

    // Post-parse validation: card-aware values_applied filtering
    if (card?.values?.declared && card.values.declared.length > 0) {
      const validValues = new Set(card.values.declared);
      analysis.values_applied = analysis.values_applied.filter((v: string) => validValues.has(v));
    }
    // If no card or all filtered out, keep Haiku's inferred values as-is

    return analysis;
  } catch (error) {
    console.error('[observer] Haiku analysis failed:', error);

    // Return fallback with whatever context we have
    // IMPORTANT: Never use responseText in fallback — that's the agent's actual output (PII)
    const fallbackReasoning = context.toolCalls.length > 0
      ? `Used tools: ${context.toolCalls.map((t) => t.name).join(', ')}`
      : 'Analysis unavailable — reasoning could not be extracted';

    return {
      alternatives: [{ id: 'analyzed', description: 'Analysis attempted but extraction failed' }],
      selected: 'analyzed',
      reasoning: fallbackReasoning,
      values_applied: ['transparency'],
    };
  } finally {
    clearTimeout(timeoutId);
  }
}

// ============================================================================
// Supabase Functions
// ============================================================================

/**
 * Fetch the active alignment card for an agent, merged with org card template (Phase 3c).
 * If the agent's org has a card template enabled (and the agent is not exempt),
 * the org template is merged as a base layer under the agent card.
 */
async function fetchCard(
  agentId: string,
  env: Env
): Promise<AlignmentCard | null> {
  try {
    const supabaseHeaders = {
      apikey: env.SUPABASE_KEY,
      Authorization: `Bearer ${env.SUPABASE_KEY}`,
    };

    // Fetch card, agent exemption status, and org card template in parallel
    const [cardResponse, agentResponse, orgCardTemplateResult] = await Promise.all([
      fetch(
        `${env.SUPABASE_URL}/rest/v1/alignment_cards?agent_id=eq.${agentId}&is_active=eq.true&limit=1`,
        { headers: supabaseHeaders }
      ),
      fetch(
        `${env.SUPABASE_URL}/rest/v1/agents?id=eq.${agentId}&select=org_card_exempt&limit=1`,
        { headers: supabaseHeaders }
      ),
      fetchOrgCardTemplateForObserver(agentId, env),
    ]);

    // Parse agent card
    let agentCard: AlignmentCard | null = null;
    if (cardResponse.ok) {
      const cards = (await cardResponse.json()) as Array<{ card_json: AlignmentCard }>;
      agentCard = cards[0]?.card_json || null;
    } else {
      console.warn(`[observer] Failed to fetch card for ${agentId}: ${cardResponse.status}`);
    }

    // Parse agent exemption status
    let orgCardExempt = false;
    if (agentResponse.ok) {
      const agents = (await agentResponse.json()) as Array<{ org_card_exempt?: boolean }>;
      if (agents.length > 0) {
        orgCardExempt = agents[0].org_card_exempt === true;
      }
    }

    // Phase 3c: Merge org card template with agent card
    const orgCardTemplate = (orgCardTemplateResult?.card_template_enabled
      ? orgCardTemplateResult.card_template
      : null) ?? null;

    return mergeOrgAndAgentCard(orgCardTemplate, agentCard as Record<string, any> | null, orgCardExempt) as AlignmentCard | null;
  } catch (error) {
    console.error(`[observer] Error fetching card for ${agentId}:`, error);
    return null;
  }
}

/**
 * Fetch org card template for an agent (Phase 3c).
 * Uses Supabase RPC. Fail-open: returns null on error.
 */
async function fetchOrgCardTemplateForObserver(
  agentId: string,
  env: Env
): Promise<{ card_template_enabled: boolean; card_template?: Record<string, any> } | null> {
  try {
    const response = await fetch(`${env.SUPABASE_URL}/rest/v1/rpc/get_org_card_template_for_agent`, {
      method: 'POST',
      headers: {
        apikey: env.SUPABASE_KEY,
        Authorization: `Bearer ${env.SUPABASE_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ p_agent_id: agentId }),
    });

    if (!response.ok) {
      console.warn(`[observer/card-tpl] RPC failed for ${agentId}: ${response.status}`);
      return { card_template_enabled: false };
    }

    return (await response.json()) as any;
  } catch (error) {
    console.warn('[observer/card-tpl] fetchOrgCardTemplate failed (fail-open):', error);
    return { card_template_enabled: false };
  }
}

/**
 * Submit a trace to Supabase
 */
async function submitTrace(
  trace: APTrace,
  verification: VerificationResult | null,
  log: GatewayLog,
  env: Env
): Promise<void> {
  // Map APTrace to database schema
  // Note: APTrace doesn't have outcome/verification - we store those separately
  const dbTrace = {
    trace_id: trace.trace_id,
    agent_id: trace.agent_id,
    card_id: trace.card_id,
    timestamp: trace.timestamp,

    // Action (stored as JSONB per schema)
    action: trace.action,

    // Decision (stored as JSONB per schema)
    decision: trace.decision,

    // Escalation (stored as JSONB per schema)
    escalation: trace.escalation,

    // Context (stored as JSONB per schema)
    context: trace.context,

    // Verification result from verifyTrace() - separate from APTrace
    verification: verification,

    // Full trace for extensibility
    trace_json: trace,
  };

  // Use upsert with on_conflict to ensure idempotency
  const response = await fetch(`${env.SUPABASE_URL}/rest/v1/traces?on_conflict=trace_id`, {
    method: 'POST',
    headers: {
      apikey: env.SUPABASE_KEY,
      Authorization: `Bearer ${env.SUPABASE_KEY}`,
      'Content-Type': 'application/json',
      Prefer: 'resolution=merge-duplicates,return=minimal',
    },
    body: JSON.stringify(dbTrace),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Failed to submit trace: ${response.status} - ${errorText}`);
  }
}

/**
 * Submit a usage event for admin tracking.
 * Non-blocking, fail-open: errors are logged but never propagate.
 */
async function submitUsageEvent(
  trace: APTrace,
  log: GatewayLog,
  env: Env
): Promise<void> {
  const eventId = `ue-${crypto.randomUUID().slice(0, 8)}`;
  const usageEvent = {
    id: eventId,
    agent_id: trace.agent_id,
    session_id: trace.context?.session_id || 'unknown',
    trace_id: trace.trace_id,
    timestamp: log.created_at,
    model: log.model || 'unknown',
    provider: log.provider || 'anthropic',
    tokens_in: log.tokens_in || 0,
    tokens_out: log.tokens_out || 0,
    duration_ms: log.duration || 0,
    gateway_log_id: log.id,
  };

  try {
    const response = await fetch(
      `${env.SUPABASE_URL}/rest/v1/usage_events`,
      {
        method: 'POST',
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
          'Content-Type': 'application/json',
          Prefer: 'return=minimal',
        },
        body: JSON.stringify(usageEvent),
      }
    );

    if (!response.ok) {
      const errorText = await response.text();
      console.warn(`[observer] Failed to submit usage event: ${response.status} - ${errorText}`);
    }
  } catch (error) {
    console.warn('[observer] Error submitting usage event:', error);
  }
}

// ============================================================================
// AIP Integrity Check Functions
// ============================================================================

/**
 * Link a gateway-created checkpoint to an observer trace.
 * The gateway creates AIP checkpoints in real-time; the observer links
 * its AAP traces to those checkpoints after processing the log.
 */
async function linkCheckpointToTrace(
  agentId: string,
  sessionId: string,
  traceId: string,
  env: Env
): Promise<void> {
  try {
    const response = await fetch(
      `${env.SUPABASE_URL}/rest/v1/integrity_checkpoints?agent_id=eq.${agentId}&session_id=eq.${sessionId}&linked_trace_id=is.null&order=timestamp.desc&limit=1`,
      {
        method: 'PATCH',
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
          'Content-Type': 'application/json',
          Prefer: 'return=minimal',
        },
        body: JSON.stringify({ linked_trace_id: traceId }),
      }
    );

    if (response.ok) {
      console.log(`[observer] Linked checkpoint to trace ${traceId}`);
    }
  } catch (error) {
    // Fail-open: linking is best-effort
    console.warn('[observer] Failed to link checkpoint to trace:', error);
  }
}


/**
 * Trigger metering rollup for all active billing accounts.
 * Idempotent — upsert-based, safe to run on every cron tick.
 */
async function triggerMeteringRollup(env: Env): Promise<void> {
  try {
    const today = new Date().toISOString().split('T')[0];

    // Get all billing accounts that have metering events today
    const response = await fetch(
      `${env.SUPABASE_URL}/rest/v1/metering_events?select=account_id&timestamp=gte.${today}T00:00:00Z&order=account_id`,
      {
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
        },
      }
    );

    if (!response.ok) {
      console.warn(`[observer/metering] Failed to fetch accounts for rollup: ${response.status}`);
      return;
    }

    const events = (await response.json()) as Array<{ account_id: string }>;
    const accountIds = [...new Set(events.map(e => e.account_id))];

    for (const accountId of accountIds) {
      const rollupResponse = await fetch(`${env.SUPABASE_URL}/rest/v1/rpc/rollup_metering`, {
        method: 'POST',
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ p_account_id: accountId, p_date: today }),
      });

      if (!rollupResponse.ok) {
        console.warn(`[observer/metering] Rollup failed for account ${accountId}: ${rollupResponse.status}`);
      }
    }

    if (accountIds.length > 0) {
      console.log(`[observer/metering] Rolled up ${accountIds.length} accounts for ${today}`);
    }
  } catch (error) {
    console.warn('[observer/metering] Error in metering rollup:', error);
  }
}

/**
 * Report daily usage to Stripe for metered billing.
 * Runs once per day at midnight UTC.
 * Queries all billing accounts with active metered subscriptions,
 * reports cumulative check_count_this_period via createUsageRecord(action:'set').
 */
async function reportDailyUsageToStripe(env: Env): Promise<void> {
  if (!env.STRIPE_SECRET_KEY) {
    console.log('[observer/stripe] No STRIPE_SECRET_KEY, skipping usage reporting');
    return;
  }

  try {
    // Import Stripe dynamically to avoid import errors when key is not set
    const { default: Stripe } = await import('stripe');
    const stripe = new Stripe(env.STRIPE_SECRET_KEY, {
      apiVersion: '2026-01-28.clover',
      httpClient: Stripe.createFetchHttpClient(),
    });

    // Fetch accounts with active metered subscriptions (checks and/or proofs)
    // Include stripe_customer_id for meter events API (proofs)
    const accountsResponse = await fetch(
      `${env.SUPABASE_URL}/rest/v1/billing_accounts?subscription_status=in.(active,trialing)&stripe_subscription_item_id=not.is.null&select=account_id,stripe_customer_id,stripe_subscription_item_id,check_count_this_period,stripe_proof_subscription_item_id,proof_count_this_period`,
      {
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
        },
      }
    );

    if (!accountsResponse.ok) {
      console.warn(`[observer/stripe] Failed to fetch accounts: ${accountsResponse.status}`);
      return;
    }

    const accounts = (await accountsResponse.json()) as Array<{
      account_id: string;
      stripe_customer_id: string;
      stripe_subscription_item_id: string;
      check_count_this_period: number;
      stripe_proof_subscription_item_id: string | null;
      proof_count_this_period: number;
    }>;

    const today = new Date().toISOString().split('T')[0];
    let reported = 0;

    // Fetch today's proof counts from usage_daily_rollup for meter event reporting.
    // Meter events are incremental (each event adds to total), so we send daily counts
    // rather than cumulative period totals.
    const proofRollupResponse = await fetch(
      `${env.SUPABASE_URL}/rest/v1/usage_daily_rollup?date=eq.${today}&proof_count=gt.0&select=account_id,proof_count`,
      {
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
        },
      }
    );
    const dailyProofCounts = new Map<string, number>();
    if (proofRollupResponse.ok) {
      const rows = (await proofRollupResponse.json()) as Array<{ account_id: string; proof_count: number }>;
      for (const row of rows) {
        dailyProofCounts.set(row.account_id, row.proof_count);
      }
    }

    for (const account of accounts) {
      try {
        const checkQuantity = account.check_count_this_period || 0;
        const checkIdempotencyKey = `${account.account_id}-checks-${today}`;

        // Report check usage via legacy createUsageRecord (cumulative, action:'set')
        await (stripe as any).subscriptionItems.createUsageRecord(
          account.stripe_subscription_item_id,
          {
            quantity: checkQuantity,
            timestamp: Math.floor(Date.now() / 1000),
            action: 'set',
          },
          { idempotencyKey: checkIdempotencyKey }
        );

        // Record check usage in stripe_usage_reports
        const checkReportId = `sur-${crypto.randomUUID().slice(0, 8)}`;
        await fetch(`${env.SUPABASE_URL}/rest/v1/stripe_usage_reports`, {
          method: 'POST',
          headers: {
            apikey: env.SUPABASE_KEY,
            Authorization: `Bearer ${env.SUPABASE_KEY}`,
            'Content-Type': 'application/json',
            Prefer: 'return=minimal',
          },
          body: JSON.stringify({
            id: checkReportId,
            account_id: account.account_id,
            stripe_subscription_item_id: account.stripe_subscription_item_id,
            reported_quantity: checkQuantity,
            idempotency_key: checkIdempotencyKey,
          }),
        });

        // Report proof usage via Stripe Meter Events API (incremental, daily count).
        // The proof price is linked to a Stripe Meter (event_name: 'zk_proof'),
        // which requires meter events instead of createUsageRecord.
        let proofQuantity = 0;
        const dailyProofCount = dailyProofCounts.get(account.account_id) || 0;
        if (dailyProofCount > 0 && account.stripe_customer_id) {
          proofQuantity = dailyProofCount;
          const proofIdentifier = `${account.account_id}-proofs-${today}`;

          await (stripe as any).billing.meterEvents.create({
            event_name: 'zk_proof',
            payload: {
              stripe_customer_id: account.stripe_customer_id,
              value: String(proofQuantity),
            },
            identifier: proofIdentifier,
            timestamp: Math.floor(Date.now() / 1000),
          });

          // Record proof usage in stripe_usage_reports
          const proofReportId = `sur-${crypto.randomUUID().slice(0, 8)}`;
          await fetch(`${env.SUPABASE_URL}/rest/v1/stripe_usage_reports`, {
            method: 'POST',
            headers: {
              apikey: env.SUPABASE_KEY,
              Authorization: `Bearer ${env.SUPABASE_KEY}`,
              'Content-Type': 'application/json',
              Prefer: 'return=minimal',
            },
            body: JSON.stringify({
              id: proofReportId,
              account_id: account.account_id,
              stripe_subscription_item_id: account.stripe_proof_subscription_item_id || 'meter_event',
              reported_quantity: proofQuantity,
              idempotency_key: proofIdentifier,
            }),
          });
        }

        // Log billing event (combined check + proof report)
        const eventId = `be-${crypto.randomUUID().slice(0, 8)}`;
        await fetch(`${env.SUPABASE_URL}/rest/v1/billing_events`, {
          method: 'POST',
          headers: {
            apikey: env.SUPABASE_KEY,
            Authorization: `Bearer ${env.SUPABASE_KEY}`,
            'Content-Type': 'application/json',
            Prefer: 'return=minimal',
          },
          body: JSON.stringify({
            event_id: eventId,
            account_id: account.account_id,
            event_type: 'usage_reported',
            details: {
              check_quantity: checkQuantity,
              proof_quantity: proofQuantity,
              date: today,
              check_idempotency_key: checkIdempotencyKey,
              proof_identifier: proofQuantity > 0
                ? `${account.account_id}-proofs-${today}`
                : null,
            },
            performed_by: 'observer_cron',
            timestamp: new Date().toISOString(),
          }),
        });

        reported++;
      } catch (error) {
        console.warn(`[observer/stripe] Failed to report usage for ${account.account_id}:`, error);
      }
    }

    if (reported > 0) {
      console.log(`[observer/stripe] Reported usage for ${reported}/${accounts.length} accounts`);
    }
  } catch (error) {
    console.warn('[observer/stripe] Error in daily usage reporting:', error);
  }
}

/**
 * Check for behavioral drift across recent traces
 */
async function checkForDrift(
  agentId: string,
  card: AlignmentCard | null,
  env: Env,
  otelExporter?: WorkersOTelExporter | null
): Promise<void> {
  if (!card) {
    return;
  }

  try {
    // Fetch recent traces for drift analysis
    const response = await fetch(
      `${env.SUPABASE_URL}/rest/v1/traces?agent_id=eq.${agentId}&order=timestamp.desc&limit=50`,
      {
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
        },
      }
    );

    if (!response.ok) {
      console.warn(`[observer] Failed to fetch traces for drift check: ${response.status}`);
      return;
    }

    const traces = (await response.json()) as Array<{ trace_json: APTrace }>;

    if (traces.length < 10) {
      // Not enough traces for meaningful drift detection
      return;
    }

    // Extract APTrace objects from database records
    const apTraces = traces.map((t) => t.trace_json);

    // Use AAP SDK drift detection - returns DriftAlert[]
    const driftAlerts: DriftAlert[] = detectDrift(card, apTraces);

    if (driftAlerts.length > 0 && otelExporter) {
      otelExporter.recordDrift(driftAlerts, apTraces.length);
    }

    // Limit to first alert to prevent subrequest overflow
    // TODO: Add proper deduplication - check if similar alert exists before storing
    if (driftAlerts.length > 0) {
      const alert = driftAlerts[0];
      await storeDriftAlert(agentId, alert, env);
      console.log(
        `[observer] Drift detected for ${agentId}: ${alert.analysis.drift_direction} (${driftAlerts.length} total alerts)`
      );
    }
  } catch (error) {
    console.error(`[observer] Drift detection failed for ${agentId}:`, error);
  }
}

/**
 * Store a drift alert in Supabase
 */
async function storeDriftAlert(
  agentId: string,
  driftAlert: DriftAlert,
  env: Env
): Promise<void> {
  // Map DriftAlert analysis to severity based on similarity score
  const severity = driftAlert.analysis.similarity_score < 0.3 ? 'high'
    : driftAlert.analysis.similarity_score < 0.5 ? 'medium' : 'low';

  const alert = {
    id: `drift-${randomHex(8)}`,
    agent_id: agentId,
    card_id: driftAlert.card_id,
    alert_type: driftAlert.analysis.drift_direction,
    severity,
    description: driftAlert.recommendation,
    drift_data: driftAlert.analysis,
    trace_ids: driftAlert.trace_ids,
  };

  try {
    const response = await fetch(`${env.SUPABASE_URL}/rest/v1/drift_alerts`, {
      method: 'POST',
      headers: {
        apikey: env.SUPABASE_KEY,
        Authorization: `Bearer ${env.SUPABASE_KEY}`,
        'Content-Type': 'application/json',
        Prefer: 'return=minimal',
      },
      body: JSON.stringify(alert),
    });

    if (!response.ok) {
      console.warn(`[observer] Failed to store drift alert: ${response.status}`);
    }
  } catch (error) {
    console.error('[observer] Error storing drift alert:', error);
  }
}

// ============================================================================
// Trace Building
// ============================================================================

/**
 * Build an APTrace conformant trace object
 */
function buildTrace(
  log: GatewayLog,
  metadata: GatewayMetadata,
  context: ExtractedContext,
  analysis: HaikuAnalysis,
  card: AlignmentCard | null
): APTrace {
  // Derive trace_id from log.id for idempotency - same log = same trace
  const traceId = `tr-${log.id.slice(-8)}`;

  // Build action name — prefer tool names, fall back to "inference"
  // Model identity is metadata (stored in parameters.model), not an action
  let actionName = 'inference';
  if (context.toolCalls.length > 0) {
    actionName = context.toolCalls.map((t) => t.name).join(', ');
  }

  // Build action object per AAP SDK Action interface
  const action: Action = {
    type: 'execute',
    name: actionName,
    category: 'bounded',
    target: {
      type: 'api',
      identifier: log.provider || 'anthropic',
    },
    parameters: {
      tokens_in: log.tokens_in,
      tokens_out: log.tokens_out,
      duration_ms: log.duration,
      model: log.model,
      ...(context.toolCalls.length > 0 && {
        tools: context.toolCalls.map((t) => t.name),
      }),
    },
  };

  // Compute confidence deterministically from context richness
  const confidence: number = context.thinking
    ? (context.thinking.length > 500 ? 0.9 : 0.6)
    : 0.3;

  // Build decision object per AAP SDK Decision interface
  const decision: Decision = {
    alternatives_considered: analysis.alternatives.map((a) => ({
      option_id: a.id,
      description: a.description,
    })),
    selected: analysis.selected,
    selection_reasoning: analysis.reasoning,
    values_applied: analysis.values_applied,
    confidence,
  };

  // Build escalation object per AAP SDK Escalation interface
  const escalation: Escalation = {
    evaluated: true,
    required: false,
    reason: 'No escalation triggers matched',
  };

  // Build the complete APTrace object (matches SDK exactly)
  const trace: APTrace = {
    trace_id: traceId,
    agent_id: metadata.agent_id,
    card_id: card?.card_id || 'ac-default',
    timestamp: log.created_at,

    action,
    decision,
    escalation,

    context: {
      session_id: metadata.session_id,
      conversation_turn: 1,
      environment: {
        gateway_version: metadata.gateway_version,
        provider: log.provider,
      },
      metadata: {
        has_thinking: !!context.thinking,
        gateway_log_id: log.id,
        success: log.success,
        tool_count: context.toolCalls.length,
        result_summary: `${log.tokens_out} tokens generated in ${log.duration}ms`,
        // Spread content classification flags for AAP SDK evaluateCondition()
        ...(analysis.content_flags || {}),
      },
    },
  };

  return trace;
}

// ============================================================================
// Enforcement Nudge Functions
// ============================================================================


/**
 * Expire stale pending nudges older than 4 hours.
 * Called during cron cycles.
 */
async function expireStaleNudges(env: Env): Promise<void> {
  try {
    const fourHoursAgo = new Date(Date.now() - 4 * 60 * 60 * 1000).toISOString();
    const response = await fetch(
      `${env.SUPABASE_URL}/rest/v1/enforcement_nudges?status=eq.pending&created_at=lt.${fourHoursAgo}`,
      {
        method: 'PATCH',
        headers: {
          apikey: env.SUPABASE_KEY,
          Authorization: `Bearer ${env.SUPABASE_KEY}`,
          'Content-Type': 'application/json',
          Prefer: 'return=representation',
        },
        body: JSON.stringify({
          status: 'expired',
          expired_at: new Date().toISOString(),
        }),
      }
    );

    if (response.ok) {
      const expired = (await response.json()) as unknown[];
      if (expired.length > 0) {
        console.log(`[observer/nudge] Expired ${expired.length} stale nudge(s)`);
      }
    } else {
      console.warn(`[observer/nudge] Failed to expire stale nudges: ${response.status}`);
    }
  } catch (error) {
    console.error('[observer/nudge] Error expiring nudges:', error);
  }
}

// ============================================================================
// Utilities
// ============================================================================

/**
 * Generate a random hex string of specified length
 */
function randomHex(length: number): string {
  const chars = '0123456789abcdef';
  let result = '';
  for (let i = 0; i < length; i++) {
    result += chars[Math.floor(Math.random() * chars.length)];
  }
  return result;
}
